{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwriting-Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "mJOsCZzng2NM",
        "outputId": "35010d64-e8ba-42f0-d3e0-9b982b180b5b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-68fa2c7a8579>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax\u001b[0m            \u001b[0;31m#activations functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m                          \u001b[0;31m#utility functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_tqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTQDMNotebookCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'to_categorical' from 'keras.utils' (/usr/local/lib/python3.7/dist-packages/keras/utils/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import cv2\t\t\t\t#opencv library\n",
        "import os\t\t\t\t#to load files present in os\n",
        "import pandas as pd\t\t\t\n",
        "import string\n",
        "import matplotlib.pyplot as plt\t\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#importing keras for neural networks\n",
        "from keras.layers import Dense, LSTM, Reshape, BatchNormalization, Input, Conv2D, MaxPool2D, Lambda, Bidirectional\n",
        "from keras.models import Model\n",
        "from keras.activations import relu, sigmoid, softmax\t\t#activations functions\n",
        "import keras.backend as K\n",
        "from keras.utils import to_categorical\t\t\t\t#utility functions\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras_tqdm import TQDMNotebookCallback\n",
        "\n",
        "from sklearn.model_selection import train_test_split\t\t#to split dataset into train and test\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#import tensorflow for CNN, also checking the version available\n",
        "import tensorflow as tf\n",
        "\n",
        "#ignore warnings in the output\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "# Check all available devices if GPU is available\n",
        "print(device_lib.list_local_devices())\n",
        "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
        "\n",
        "#we have loaded a file which contains all the words present, this helps in indentification and matching of words in images\n",
        "with open('parser/words.txt') as f:\n",
        "    contents = f.readlines()\n",
        "lines = [line.strip() for line in contents] \n",
        "lines[0]\n",
        "\n",
        "\n",
        "max_label_len = 0\n",
        "\n",
        "char_list = \"!\\\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\" \n",
        "\n",
        "# string.ascii_letters + string.digits (Chars & Digits)\n",
        "# or \n",
        "# \"!\\\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\"\n",
        "\n",
        "print(char_list, len(char_list))\n",
        "\n",
        "def encode_to_labels(txt):\n",
        "    # encoding each output word into digits\n",
        "    dig_lst = []\n",
        "    for index, chara in enumerate(txt):\n",
        "        dig_lst.append(char_list.index(chara))\n",
        "        \n",
        "    return dig_lst\n",
        "\n",
        "#declaring some variables\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "RECORDS_COUNT = 10000\n",
        "train_images = []\n",
        "train_labels = []\n",
        "train_input_length = []\n",
        "train_label_length = []\n",
        "train_original_text = []\n",
        "\n",
        "valid_images = []\n",
        "valid_labels = []\n",
        "valid_input_length = []\n",
        "valid_label_length = []\n",
        "valid_original_text = []\n",
        "\n",
        "inputs_length = []\n",
        "labels_length = []\n",
        "\n",
        "\n",
        "def process_image(img):\n",
        "    \"\"\"\n",
        "\tPreprocessing image is a necessary step, it is done before we give them as input to CNN\n",
        "\tWe make all the images of similar sizes and normalize them i.e. to convert them into numpy arrays\n",
        "    Converts image to shape (32, 128, 1) & normalize\n",
        "    \"\"\"\n",
        "    w, h = img.shape\n",
        "    \n",
        "#     _, img = cv2.threshold(img, \n",
        "#                            128, \n",
        "#                            255, \n",
        "#                            cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "    \n",
        "    # Aspect Ratio Calculation\n",
        "    new_w = 32\n",
        "    new_h = int(h * (new_w / w))\n",
        "    img = cv2.resize(img, (new_h, new_w))\n",
        "    w, h = img.shape\n",
        "    \n",
        "    img = img.astype('float32')\n",
        "    \n",
        "    # Converts each to (32, 128, 1)\n",
        "    if w < 32:\n",
        "        add_zeros = np.full((32-w, h), 255)\n",
        "        img = np.concatenate((img, add_zeros))\n",
        "        w, h = img.shape\n",
        "    \n",
        "    if h < 128:\n",
        "        add_zeros = np.full((w, 128-h), 255)\n",
        "        img = np.concatenate((img, add_zeros), axis=1)\n",
        "        w, h = img.shape\n",
        "        \n",
        "    if h > 128 or w > 32:\n",
        "        dim = (128,32)\n",
        "        img = cv2.resize(img, dim)\n",
        "    \n",
        "    img = cv2.subtract(255, img)\n",
        "    \n",
        "    img = np.expand_dims(img, axis=2)\n",
        "    \n",
        "    # Normalize \n",
        "    img = img / 255\n",
        "    \n",
        "    return img\n",
        "\n",
        "\n",
        "#Train and validation set generation and split\n",
        "for index, line in enumerate(lines):\n",
        "    splits = line.split(' ')\n",
        "    status = splits[1]\n",
        "    \n",
        "    if status == 'ok':\n",
        "        word_id = splits[0]\n",
        "        word = \"\".join(splits[8:])\n",
        "        \n",
        "        splits_id = word_id.split('-')\n",
        "        filepath = 'words/{}/{}-{}/{}.png'.format(splits_id[0], \n",
        "                                                  splits_id[0], \n",
        "                                                  splits_id[1], \n",
        "                                                  word_id)\n",
        "        \n",
        "        # process image\n",
        "        img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)\n",
        "        try:\n",
        "            img = process_image(img)\n",
        "        except:\n",
        "            continue\n",
        "            \n",
        "        # process label\n",
        "        try:\n",
        "            label = encode_to_labels(word)\n",
        "        except:\n",
        "            continue\n",
        "        \n",
        "        if index % 10 == 0:\n",
        "            valid_images.append(img)\n",
        "            valid_labels.append(label)\n",
        "            valid_input_length.append(31)\n",
        "            valid_label_length.append(len(word))\n",
        "            valid_original_text.append(word)\n",
        "        else:\n",
        "            train_images.append(img)\n",
        "            train_labels.append(label)\n",
        "            train_input_length.append(31)\n",
        "            train_label_length.append(len(word))\n",
        "            train_original_text.append(word)\n",
        "        \n",
        "        if len(word) > max_label_len:\n",
        "            max_label_len = len(word)\n",
        "    \n",
        "    if index >= RECORDS_COUNT:\n",
        "        break\n",
        "\n",
        "train_padded_label = pad_sequences(train_labels, \n",
        "                             maxlen=max_label_len, \n",
        "                             padding='post',\n",
        "                             value=len(char_list))\n",
        "\n",
        "valid_padded_label = pad_sequences(valid_labels, \n",
        "                             maxlen=max_label_len, \n",
        "                             padding='post',\n",
        "                             value=len(char_list))\n",
        "\n",
        "#print the shape\n",
        "train_padded_label.shape, valid_padded_label.shape\t\n",
        "\n",
        "#converting them to numpy\n",
        "train_images = np.asarray(train_images)\n",
        "train_input_length = np.asarray(train_input_length)\n",
        "train_label_length = np.asarray(train_label_length)\n",
        "\n",
        "valid_images = np.asarray(valid_images)\n",
        "valid_input_length = np.asarray(valid_input_length)\n",
        "valid_label_length = np.asarray(valid_label_length)\n",
        "\n",
        "# input with shape of height=32 and width=128 \n",
        "inputs = Input(shape=(32,128,1))\n",
        " \n",
        "# convolution layer with kernel size (3,3)\n",
        "conv_1 = Conv2D(64, (3,3), activation = 'relu', padding='same')(inputs)\n",
        "# poolig layer with kernel size (2,2)\n",
        "pool_1 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_1)\n",
        " \n",
        "conv_2 = Conv2D(128, (3,3), activation = 'relu', padding='same')(pool_1)\n",
        "pool_2 = MaxPool2D(pool_size=(2, 2), strides=2)(conv_2)\n",
        " \n",
        "conv_3 = Conv2D(256, (3,3), activation = 'relu', padding='same')(pool_2)\n",
        " \n",
        "conv_4 = Conv2D(256, (3,3), activation = 'relu', padding='same')(conv_3)\n",
        "# poolig layer with kernel size (2,1)\n",
        "pool_4 = MaxPool2D(pool_size=(2, 1))(conv_4)\n",
        " \n",
        "conv_5 = Conv2D(512, (3,3), activation = 'relu', padding='same')(pool_4)\n",
        "# Batch normalization layer\n",
        "batch_norm_5 = BatchNormalization()(conv_5)\n",
        " \n",
        "conv_6 = Conv2D(512, (3,3), activation = 'relu', padding='same')(batch_norm_5)\n",
        "batch_norm_6 = BatchNormalization()(conv_6)\n",
        "pool_6 = MaxPool2D(pool_size=(2, 1))(batch_norm_6)\n",
        " \n",
        "conv_7 = Conv2D(512, (2,2), activation = 'relu')(pool_6)\n",
        " \n",
        "squeezed = Lambda(lambda x: K.squeeze(x, 1))(conv_7)\n",
        " \n",
        "# bidirectional LSTM layers with units=128\n",
        "blstm_1 = Bidirectional(LSTM(256, return_sequences=True, dropout = 0.2))(squeezed)\n",
        "blstm_2 = Bidirectional(LSTM(256, return_sequences=True, dropout = 0.2))(blstm_1)\n",
        " \n",
        "outputs = Dense(len(char_list)+1, activation = 'softmax')(blstm_2)\n",
        "# model to be used at test time\n",
        "act_model = Model(inputs, outputs)\n",
        "act_model.summary()\n",
        "\n",
        "the_labels = Input(name='the_labels', shape=[max_label_len], dtype='float32')\n",
        "input_length = Input(name='input_length', shape=[1], dtype='int64')\n",
        "label_length = Input(name='label_length', shape=[1], dtype='int64')\n",
        "\n",
        "def ctc_lambda_func(args):\n",
        "    y_pred, labels, input_length, label_length = args\n",
        "    \n",
        "    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)\n",
        "\n",
        "loss_out = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([outputs, the_labels, input_length, label_length])\n",
        "\n",
        "#model to be used at training time\n",
        "model = Model(inputs=[inputs, the_labels, input_length, label_length], outputs=loss_out)\n",
        "\n",
        "batch_size = 8\n",
        "epochs = 30\n",
        "e = str(epochs)\n",
        "optimizer_name = 'sgd'\n",
        "\n",
        "model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer = optimizer_name, metrics=['accuracy'])\n",
        "\n",
        "filepath=\"{}o-{}r-{}e-{}t-{}v.hdf5\".format(optimizer_name,\n",
        "                                          str(RECORDS_COUNT),\n",
        "                                          str(epochs),\n",
        "                                          str(train_images.shape[0]),\n",
        "                                          str(valid_images.shape[0]))\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "callbacks_list = [checkpoint]\n",
        "history = model.fit(x=[train_images, train_padded_label, train_input_length, train_label_length],\n",
        "                    y=np.zeros(len(train_images)),\n",
        "                    batch_size=batch_size, \n",
        "                    epochs=epochs, \n",
        "                    validation_data=([valid_images, valid_padded_label, valid_input_length, valid_label_length], [np.zeros(len(valid_images))]),\n",
        "                    verbose=2,\n",
        "                    callbacks=callbacks_list)\n",
        "\n",
        "# load the saved best model weights\n",
        "act_model.load_weights(filepath)\n",
        "\n",
        "# predict outputs on validation images\n",
        "prediction = act_model.predict(valid_images)\n",
        " \n",
        "# use CTC decoder\n",
        "decoded = K.ctc_decode(prediction, \n",
        "                       input_length=np.ones(prediction.shape[0]) * prediction.shape[1],\n",
        "                       greedy=True)[0][0]\n",
        "out = K.get_value(decoded)\n",
        "\n",
        "import Levenshtein as lv\n",
        "\n",
        "total_jaro = 0\n",
        "total_rati = 0\n",
        "# see the results\n",
        "for i, x in enumerate(out):\n",
        "    letters=''\n",
        "    for p in x:\n",
        "        if int(p) != -1:\n",
        "            letters+=char_list[int(p)]\n",
        "    total_jaro+=lv.jaro(letters, valid_original_text[i])\n",
        "    total_rati+=lv.ratio(letters, valid_original_text[i])\n",
        "\n",
        "print('jaro :', total_jaro/len(out))\n",
        "print('ratio:', total_rati/len(out))\n",
        "\n",
        "\n",
        "# predict outputs on validation images\n",
        "prediction = act_model.predict(train_images[150:170])\n",
        " \n",
        "# use CTC decoder\n",
        "decoded = K.ctc_decode(prediction,   \n",
        "                       input_length=np.ones(prediction.shape[0]) * prediction.shape[1],\n",
        "                       greedy=True)[0][0]\n",
        "\n",
        "out = K.get_value(decoded)\n",
        "\n",
        "# see the results\n",
        "for i, x in enumerate(out):\n",
        "    print(\"original_text =  \", train_original_text[150+i])\n",
        "    print(\"predicted text = \", end = '')\n",
        "    for p in x:\n",
        "        if int(p) != -1:\n",
        "            print(char_list[int(p)], end = '')\n",
        "    plt.imshow(train_images[150+i].reshape(32,128), cmap=plt.cm.gray)\n",
        "    plt.show()\n",
        "    print('\\n')\n",
        "\n",
        "# plot accuracy and loss\n",
        "def plotgraph(epochs, acc, val_acc):\n",
        "    # Plot training & validation accuracy values\n",
        "    plt.plot(epochs, acc, 'b')\n",
        "    plt.plot(epochs, val_acc, 'r')\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper left')\n",
        "    plt.show()\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1,len(loss)+1)\n",
        "plotgraph(epochs, loss, val_loss)\n",
        "plotgraph(epochs, acc, val_acc)\n",
        "# get best model index\n",
        "minimum_val_loss = np.min(history.history['val_loss'])\n",
        "best_model_index = np.where(history.history['val_loss'] == minimum_val_loss)[0][0]\n",
        "\n",
        "best_loss = str(history.history['loss'][best_model_index])\n",
        "best_acc = str(history.history['accuracy'][best_model_index])\n",
        "best_val_loss = str(history.history['val_loss'][best_model_index])\n",
        "best_val_acc = str(history.history['val_accuracy'][best_model_index])"
      ]
    }
  ]
}